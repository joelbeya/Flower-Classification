{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "**`Imports`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import copy\n",
    "import numpy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Converting the XMLs to CSV file`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ObservationId</th>\n",
       "      <th>Species</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MediaId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>pierre bonnet</td>\n",
       "      <td>493</td>\n",
       "      <td>Flower</td>\n",
       "      <td>2011-3-20</td>\n",
       "      <td>Asteraceae</td>\n",
       "      <td>Bellis</td>\n",
       "      <td>43.65188</td>\n",
       "      <td>Palavas-les-Flots</td>\n",
       "      <td>3.86169</td>\n",
       "      <td>23116</td>\n",
       "      <td>Bellis perennis L.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15580</th>\n",
       "      <td>mathieu menand</td>\n",
       "      <td>4477</td>\n",
       "      <td>Flower</td>\n",
       "      <td>2007-7-7</td>\n",
       "      <td>Ranunculaceae</td>\n",
       "      <td>Anemone</td>\n",
       "      <td>None</td>\n",
       "      <td>Aston</td>\n",
       "      <td>None</td>\n",
       "      <td>28135</td>\n",
       "      <td>Anemone alpina L.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97913</th>\n",
       "      <td>herve goeau</td>\n",
       "      <td>4516</td>\n",
       "      <td>Flower</td>\n",
       "      <td>2013-4-21</td>\n",
       "      <td>Ranunculaceae</td>\n",
       "      <td>Ficaria</td>\n",
       "      <td>48.84401</td>\n",
       "      <td>Vert-le-Petit</td>\n",
       "      <td>2.35995</td>\n",
       "      <td>37273</td>\n",
       "      <td>Ficaria verna Huds.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101501</th>\n",
       "      <td>liliane roubaudi</td>\n",
       "      <td>2394</td>\n",
       "      <td>Flower</td>\n",
       "      <td>2012-4-11</td>\n",
       "      <td>Cistaceae</td>\n",
       "      <td>Cistus</td>\n",
       "      <td>None</td>\n",
       "      <td>Narbonne</td>\n",
       "      <td>None</td>\n",
       "      <td>25202</td>\n",
       "      <td>Cistus albidus L.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76867</th>\n",
       "      <td>herve goeau</td>\n",
       "      <td>5148</td>\n",
       "      <td>Flower</td>\n",
       "      <td>2013-3-24</td>\n",
       "      <td>Salicaceae</td>\n",
       "      <td>Salix</td>\n",
       "      <td>48.8567</td>\n",
       "      <td>Sainte-Geneviève-des-Bois</td>\n",
       "      <td>2.24104</td>\n",
       "      <td>11603</td>\n",
       "      <td>Salix caprea L.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Author ClassId Content       Date         Family    Genus  \\\n",
       "MediaId                                                                        \n",
       "1378        pierre bonnet     493  Flower  2011-3-20     Asteraceae   Bellis   \n",
       "15580      mathieu menand    4477  Flower   2007-7-7  Ranunculaceae  Anemone   \n",
       "97913         herve goeau    4516  Flower  2013-4-21  Ranunculaceae  Ficaria   \n",
       "101501   liliane roubaudi    2394  Flower  2012-4-11      Cistaceae   Cistus   \n",
       "76867         herve goeau    5148  Flower  2013-3-24     Salicaceae    Salix   \n",
       "\n",
       "         Latitude                   Location Longitude ObservationId  \\\n",
       "MediaId                                                                \n",
       "1378     43.65188          Palavas-les-Flots   3.86169         23116   \n",
       "15580        None                      Aston      None         28135   \n",
       "97913    48.84401              Vert-le-Petit   2.35995         37273   \n",
       "101501       None                   Narbonne      None         25202   \n",
       "76867     48.8567  Sainte-Geneviève-des-Bois   2.24104         11603   \n",
       "\n",
       "                     Species Vote  \n",
       "MediaId                            \n",
       "1378      Bellis perennis L.    3  \n",
       "15580      Anemone alpina L.    3  \n",
       "97913    Ficaria verna Huds.    4  \n",
       "101501     Cistus albidus L.    4  \n",
       "76867        Salix caprea L.    3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDirectory = \"small_dataset_train/\"\n",
    "\n",
    "# Parses all XML files in the directory, then return a dataframe of all the infos\n",
    "def parseFilesInDirectory(directory):\n",
    "    flowers = []\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".xml\"):\n",
    "            flowers = flowers + getInfosfromXML(os.path.join(directory, file))\n",
    "            \n",
    "    return flowers\n",
    "\n",
    "# Parses the XML file to keep the relevant informations only, then return a dataframe\n",
    "def getInfosfromXML(fileContent):\n",
    "    root = ET.parse(fileContent).getroot()\n",
    "    \n",
    "    # We want a list of dictionnaries\n",
    "    flowerInfos = []\n",
    "    flowerInfos.append(\n",
    "                    dict(MediaId = root.find(\"MediaId\").text,\n",
    "                         ObservationId = root.find(\"ObservationId\").text,\n",
    "                         ClassId = root.find(\"ClassId\").text,\n",
    "                         Content = root.find(\"Content\").text,\n",
    "                         Family = root.find(\"Family\").text,\n",
    "                         Genus = root.find(\"Genus\").text,\n",
    "                         Species = root.find(\"Species\").text,\n",
    "                         Date = root.find(\"Date\").text,\n",
    "                         Location = root.find(\"Location\").text,\n",
    "                         Latitude = root.find(\"Latitude\").text,\n",
    "                         Longitude = root.find(\"Longitude\").text,\n",
    "                         Author = root.find(\"Author\").text,\n",
    "                         Vote = root.find(\"Vote\").text\n",
    "                        )\n",
    "                 )\n",
    "\n",
    "    return flowerInfos\n",
    "\n",
    "flowers = pandas.DataFrame(parseFilesInDirectory(dataDirectory + \"train/\"))\n",
    "flowers.set_index(\"MediaId\", inplace = True)\n",
    "\n",
    "flowers.to_csv(dataDirectory + \"Flowers.csv\")\n",
    "flowers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Converting the XMLs to CSV file`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'small_dataset_train/'\n",
    "# check path\n",
    "# os.path.isfile(data_dir)\n",
    "os.path.isdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Transformation of the training and validation sets`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays to normalization\n",
    "normalize_mean = np.array([0.485, 0.456, 0.406])\n",
    "normalize_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {}\n",
    "\n",
    "# transforms to train data set\n",
    "data_transforms['train'] = transforms.Compose([\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(180),\n",
    "        ]),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        normalize_mean,\n",
    "        normalize_std)\n",
    "    ])\n",
    "\n",
    "# transforms to valid data set\n",
    "data_transforms['valid'] = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        normalize_mean,\n",
    "        normalize_std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Load the datasets with ImageFolder`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train']\n",
      "['train']\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "image_datasets = {}\n",
    "image_datasets = ImageFolder(root='small_dataset_train', transform=data_transforms['train'])\n",
    "print(image_datasets.classes)\n",
    "\n",
    "valid_dataset_to_split = ImageFolder(root='small_dataset_train', transform=data_transforms['valid'])\n",
    "print(valid_dataset_to_split.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Obtain validation and training datasets that will be used to evaluate the network`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ImageFolder' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6c06dd395de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_data_index_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset_to_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data_index_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset_to_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_index_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ImageFolder' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "valid_data_index_list = []\n",
    "test_data_index_list = []\n",
    "\n",
    "for index in range(0, len(valid_dataset_to_split), 2):\n",
    "    valid_data_index_list.append(index)\n",
    "    test_data_index_list.append(index+1)\n",
    "\n",
    "image_datasets['valid_data'] = list(Subset(valid_dataset_to_split, valid_data_index_list))\n",
    "image_datasets['test_data'] = list(Subset(valid_dataset_to_split, test_data_index_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Using the image datasets and the transforms, define the dataloaders`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataloaders['train_data'] = torch.utils.data.DataLoader(image_datasets['train_data'], batch_size=32, shuffle=True, num_workers=32)\n",
    "dataloaders['valid_data'] = torch.utils.data.DataLoader(image_datasets['valid_data'], batch_size=23, shuffle=False, num_workers=32)\n",
    "dataloaders['test_data'] = torch.utils.data.DataLoader(image_datasets['test_data'], batch_size=23, shuffle=False, num_workers=32)\n",
    "print(f\"Train data: {len(dataloaders['train_data'].dataset)} images / {len(dataloaders['train_data'])} batches\")\n",
    "print(f\"Valid data: {len(dataloaders['valid_data'].dataset)} images / {len(dataloaders['valid_data'])} batches\")\n",
    "print(f\"Test  data: {len(dataloaders['test_data'].dataset)} images / {len(dataloaders['test_data'])} batches\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
